import torch
import torch.nn as nn
import torch.nn.functional as F

# --- Helper Modules ---

class DWSConv(nn.Module):
    """Depthwise Separable Convolution - íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„±ì„ ìœ„í•œ í•µì‹¬ ëª¨ë“ˆ"""
    def __init__(self, nIn, nOut, kSize, stride=1, padding=0, dilation=(1, 1), bn_acti=True, bias=False):
        super().__init__()
        self.depthwise = nn.Conv2d(nIn, nIn, kernel_size=kSize, stride=stride, padding=padding,
                                   dilation=dilation, groups=nIn, bias=bias)
        self.pointwise = nn.Conv2d(nIn, nOut, kernel_size=1, stride=1, padding=0, bias=bias)
        self.bn_acti = bn_acti
        if self.bn_acti:
            self.bn = nn.BatchNorm2d(nOut, eps=1e-3)
            self.acti = nn.SiLU(inplace=True)

    def forward(self, x):
        x = self.depthwise(x)
        x = self.pointwise(x)
        if self.bn_acti:
            x = self.bn(x)
            x = self.acti(x)
        return x

class Conv(nn.Module):
    """1x1 Convë‚˜ Grouped Convë¥¼ ìœ„í•œ í‘œì¤€ ëª¨ë“ˆ"""
    def __init__(self, nIn, nOut, kSize, stride, padding, dilation=(1, 1), groups=1, bn_acti=False, bias=False):
        super().__init__()
        self.bn_acti = bn_acti
        self.conv = nn.Conv2d(nIn, nOut, kernel_size=kSize, stride=stride, padding=padding,
                              dilation=dilation, groups=groups, bias=bias)
        if self.bn_acti:
            self.bn = nn.BatchNorm2d(nOut, eps=1e-3)
            self.acti = nn.SiLU(inplace=True)

    def forward(self, input):
        output = self.conv(input)
        if self.bn_acti:
            output = self.bn(output)
            output = self.acti(output)
        return output

class DownSamplingBlock(nn.Module):
    """íš¨ìœ¨ì ì¸ ë‹¤ìš´ìƒ˜í”Œë§ - HWNet ì •ì²´ì„± ìœ ì§€"""
    def __init__(self, nIn, nOut):
        super().__init__()
        self.nIn, self.nOut = nIn, nOut
        nConv = nOut - nIn if self.nIn < self.nOut else nOut
        self.conv3x3 = DWSConv(nIn, nConv, kSize=3, stride=2, padding=1, bn_acti=False)
        self.max_pool = nn.MaxPool2d(2, stride=2, padding=0)
        self.bn = nn.BatchNorm2d(nOut, eps=1e-3)
        self.acti = nn.SiLU(inplace=True)

    def forward(self, input):
        output = self.conv3x3(input)
        if self.nIn < self.nOut:
            output = torch.cat([output, self.max_pool(input)], 1)
        return self.acti(self.bn(output))

def Split(x, p):
    """ì±„ë„ ë¶„í•  - HWNet/LCNetì˜ í•µì‹¬ ì •ì²´ì„±"""
    c = int(x.size(1))
    c1 = round(c * (1 - p))
    return x[:, :c1, :, :].contiguous(), x[:, c1:, :, :].contiguous()

class TCA(nn.Module):
    """Triple Context Aggregation - ê°•í™”ëœ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì§• ì¶”ì¶œ"""
    def __init__(self, c, d=1, kSize=3):
        super().__init__()
        self.conv3x3 = DWSConv(c, c, kSize, 1, padding=1, bn_acti=True)
        self.dconv3x3 = Conv(c, c, (kSize, kSize), 1, padding=(1, 1), groups=c, bn_acti=True)
        self.ddconv3x3 = Conv(c, c, (kSize, kSize), 1, padding=(d, d), groups=c, dilation=(d, d), bn_acti=True)
        self.bn = nn.BatchNorm2d(c, eps=1e-3)
        self.acti = nn.SiLU(inplace=True)

    def forward(self, input):
        br = self.conv3x3(input)
        br1 = self.dconv3x3(br)
        br2 = self.ddconv3x3(br)
        br = br + br1 + br2
        return self.acti(self.bn(br))

class PCT(nn.Module):
    """Partial Channel Transformation - ìµœì í™”ëœ HWNet ë³‘ëª© êµ¬ì¡°"""
    def __init__(self, nIn, d=1, p=0.22):  # pë¥¼ 0.25â†’0.22ë¡œ ê°ì†Œí•˜ì—¬ TCA ì±„ë„ ì¦ê°€
        super().__init__()
        self.p = p
        c = nIn - round(nIn * (1 - p))
        self.TCA = TCA(c, d)
        self.conv1x1 = Conv(nIn, nIn, 1, 1, padding=0, bn_acti=True)

    def forward(self, input):
        x1, x2 = Split(input, self.p)
        x2 = self.TCA(x2)
        output = torch.cat([x1, x2], dim=1)
        return self.conv1x1(output) + input

class LightDecoderBlock(nn.Module):
    """ê²½ëŸ‰ ë””ì½”ë” ë¸”ë¡"""
    def __init__(self, in_channels, skip_channels, out_channels):
        super().__init__()
        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        self.conv = nn.Sequential(
            DWSConv(in_channels + skip_channels, out_channels, 3, 1, padding=1, bn_acti=True),
            DWSConv(out_channels, out_channels, 3, 1, padding=1, bn_acti=True)
        )

    def forward(self, x, skip_x):
        x = self.up(x)
        x = torch.cat([x, skip_x], dim=1)
        return self.conv(x)

class MorphGradientFocus(nn.Module):
    """ëª¨í´ë¡œì§€ ê¸°ë°˜ ì—£ì§€ ê°•í™” - íŒŒë¼ë¯¸í„° íš¨ìœ¨ì """
    def __init__(self, in_channels, k=3):
        super().__init__()
        self.pad  = k // 2
        self.fuse = Conv(in_channels + 1, in_channels, 1, 1, padding=0, bn_acti=True)

    def forward(self, x):
        intensity = x.mean(dim=1, keepdim=True)
        dilated = F.max_pool2d(intensity, 3, stride=1, padding=self.pad)
        eroded  = -F.max_pool2d(-intensity, 3, stride=1, padding=self.pad)
        return self.fuse(torch.cat([x, dilated - eroded], dim=1))

class EnhancedSE(nn.Module):
    """Enhanced Squeeze-and-Excitation - ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ê°•í™”ëœ ì–´í…ì…˜"""
    def __init__(self, channels, reduction=14):  # reductionì„ 16â†’14ë¡œ ê°ì†Œí•˜ì—¬ ë” ê°•í•œ ì–´í…ì…˜
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)  # max pooling ì¶”ê°€ë¡œ ë” í’ë¶€í•œ ì •ë³´
        reduced_channels = max(1, channels // reduction)
        
        self.fc = nn.Sequential(
            nn.Linear(channels, reduced_channels, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(reduced_channels, channels, bias=False)
        )
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        b, c, _, _ = x.size()
        
        # í‰ê· ê³¼ ìµœëŒ€ê°’ ëª¨ë‘ í™œìš©í•˜ì—¬ ë” í’ë¶€í•œ ì–´í…ì…˜
        avg_out = self.fc(self.avg_pool(x).view(b, c))
        max_out = self.fc(self.max_pool(x).view(b, c))
        
        attention = self.sigmoid(avg_out + max_out).view(b, c, 1, 1)
        return x * attention

# --- ìµœì¢… ì œì¶œ ëª¨ë¸: HWNetUltra_v3 (0.4 IoU ë‹¬ì„± ëª©í‘œ) ---
class submission_HWNetUltra_v3(nn.Module):
    def __init__(self, in_channels=3, num_classes=1):
        super().__init__()
        # 0.4 IoU ë‹¬ì„±ì„ ìœ„í•œ ìµœì í™”ëœ ì„¤ì •
        block_1 = 2  # ìœ ì§€
        block_2 = 2  # ìœ ì§€ (íŒŒë¼ë¯¸í„° ì œì–´)
        C = 9        # 8â†’9ë¡œ ì¦ê°€ (í‘œí˜„ë ¥ í–¥ìƒ)
        P = 0.22     # 0.25â†’0.22ë¡œ ê°ì†Œ (TCA ì±„ë„ ì¦ê°€)
        dilation_block_1 = [2, 3]
        dilation_block_2 = [2, 4]  # ìœ ì§€

        # ì—£ì§€ ê°•í™” ëª¨ë“ˆ (ì„±ëŠ¥ í•µì‹¬ - ìœ ì§€)
        self.edge_focus = MorphGradientFocus(in_channels)
        
        # ê°•í™”ëœ ì´ˆê¸° íŠ¹ì§• ì¶”ì¶œ (3ë ˆì´ì–´ë¡œ í™•ì¥)
        self.Init_Block = nn.Sequential(
            DWSConv(in_channels, C, 3, 2, padding=1, bn_acti=True),
            DWSConv(C, C, 3, 1, padding=1, bn_acti=True),
            DWSConv(C, C, 3, 1, padding=1, bn_acti=True)  # ì¶”ê°€ ë ˆì´ì–´ë¡œ ë” í’ë¶€í•œ ì´ˆê¸° íŠ¹ì§•
        )

        # 1ë‹¨ê³„ ì¸ì½”ë”
        self.LC_Block_1 = nn.Sequential()
        self.LC_Block_1.add_module("downsample", DownSamplingBlock(C, C * 2))
        for i in range(block_1):
            self.LC_Block_1.add_module(f"LC_Module_1_{i}", PCT(C * 2, d=dilation_block_1[i], p=P))

        # 2ë‹¨ê³„ ì¸ì½”ë”
        self.LC_Block_2 = nn.Sequential()
        self.LC_Block_2.add_module("downsample", DownSamplingBlock(C * 2, C * 4))
        for i in range(block_2):
            self.LC_Block_2.add_module(f"LC_Module_2_{i}", PCT(C * 4, d=dilation_block_2[i], p=P))
        
        # ê°•í™”ëœ ì–´í…ì…˜ (reduction ê°ì†Œë¡œ ë” ê°•í•œ ì–´í…ì…˜)
        self.attention = EnhancedSE(C * 4, reduction=14)
        
        # ë””ì½”ë”
        self.dec2 = LightDecoderBlock(C * 4, C * 2, C * 2)
        self.dec1 = LightDecoderBlock(C * 2, C, C)
        
        # ìµœì¢… ì¶œë ¥
        self.final_up = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
            DWSConv(C, C, 3, 1, padding=1, bn_acti=True),
            nn.Conv2d(C, num_classes, kernel_size=1)
        )

    def forward(self, input):
        # ì—£ì§€ ê°•í™” (ì„±ëŠ¥ í•µì‹¬ ìœ ì§€)
        x_init = self.edge_focus(input)
        
        # ê°•í™”ëœ ì¸ì½”ë”
        x0 = self.Init_Block(x_init)
        x1 = self.LC_Block_1(x0)
        x2 = self.LC_Block_2(x1)
        
        # ê°•í™”ëœ ì–´í…ì…˜ ì ìš©
        x2 = self.attention(x2)
        
        # ë””ì½”ë”
        d2 = self.dec2(x2, x1)
        d1 = self.dec1(d2, x0)
        
        # ìµœì¢… ì¶œë ¥
        return self.final_up(d1)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ë° íŒŒë¼ë¯¸í„° ê²€ì¦
    num_classes = 21
    net = submission_HWNetUltra_v3(in_channels=3, num_classes=num_classes)
    p = sum(p.numel() for p in net.parameters() if p.requires_grad)
    print(f"Model: HWNetUltra_v3 (0.4 IoU ë‹¬ì„± ëª©í‘œ)")
    print(f"Trainable Params: {p:,} ({p/1e3:.2f} K)")
    
    # 1ë§Œ ë¯¸ë§Œ ëª©í‘œ ê²€ì¦
    if p < 10000:
        print(f"âœ… ëª©í‘œ ë‹¬ì„±: {p}/10,000 ({10000-p} ì—¬ìœ )")
    elif p <= 17000:
        print(f"âš ï¸  í—ˆìš© ë²”ìœ„ ë‚´: {p}/17,000 (hard cap)")
    else:
        print(f"âŒ íŒŒë¼ë¯¸í„° ì´ˆê³¼: {p}/17,000 ({p-17000} ì´ˆê³¼)")

    try:
        x = torch.randn(1, 3, 256, 256)
        y = net(x)
        print(f"Input shape: {x.shape}")
        print(f"Output shape: {y.shape}")
        assert y.shape == (1, num_classes, 256, 256)
        print("âœ… ëª¨ë¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ í†µê³¼")
        
        # ë‹¤ì–‘í•œ í´ë˜ìŠ¤ ìˆ˜ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸
        for nc in [1, 2, 21]:
            net_test = submission_HWNetUltra_v3(in_channels=3, num_classes=nc)
            y_test = net_test(x)
            assert y_test.shape == (1, nc, 256, 256)
            print(f"âœ… {nc} í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸ í†µê³¼")
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
    # íŒŒë¼ë¯¸í„° ë¶„ì„
    print("\nğŸ“Š ì£¼ìš” ì»´í¬ë„ŒíŠ¸ë³„ íŒŒë¼ë¯¸í„°:")
    total_params = 0
    component_params = {}
    
    for name, module in net.named_modules():
        if len(list(module.children())) == 0:  # leaf modules
            params = sum(p.numel() for p in module.parameters())
            if params > 0:
                total_params += params
                # ì£¼ìš” ì»´í¬ë„ŒíŠ¸ë³„ë¡œ ê·¸ë£¹í™”
                if 'edge_focus' in name:
                    component_params['EdgeFocus'] = component_params.get('EdgeFocus', 0) + params
                elif 'Init_Block' in name:
                    component_params['InitBlock'] = component_params.get('InitBlock', 0) + params
                elif 'LC_Block_1' in name:
                    component_params['Encoder1'] = component_params.get('Encoder1', 0) + params
                elif 'LC_Block_2' in name:
                    component_params['Encoder2'] = component_params.get('Encoder2', 0) + params
                elif 'attention' in name:
                    component_params['Attention'] = component_params.get('Attention', 0) + params
                elif 'dec' in name:
                    component_params['Decoder'] = component_params.get('Decoder', 0) + params
                elif 'final_up' in name:
                    component_params['FinalUp'] = component_params.get('FinalUp', 0) + params
    
    for comp, params in component_params.items():
        print(f"  {comp}: {params:,} ({params/total_params*100:.1f}%)")
    print(f"Total: {total_params:,}")
    
    # v2ì™€ ë¹„êµ
    print(f"\nğŸ“ˆ v2 ëŒ€ë¹„ ë³€í™”:")
    print(f"  íŒŒë¼ë¯¸í„°: 7,150 â†’ {total_params:,} (+{total_params-7150:,})")
    print(f"  ì¦ê°€ìœ¨: +{(total_params-7150)/7150*100:.1f}%")
    print(f"  ëª©í‘œ ì„±ëŠ¥: 0.3944 â†’ 0.40+ (ì˜ˆìƒ)") 