import torch
import torch.nn as nn
import torch.nn.functional as F

# --- MicroNetv6: ì„±ëŠ¥ í–¥ìƒ + í˜ì‹ ì  ê¸°ìˆ  ë„ì… ---

class SeparableConv2d(nn.Module):
    """Depthwise separable convolution - í•µì‹¬ íš¨ìœ¨ ëª¨ë“ˆ"""
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=True):
        super().__init__()
        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels, bias=False)
        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)
        self.bn = nn.BatchNorm2d(in_channels, eps=1e-3)

    def forward(self, x):
        out = self.depthwise(x)
        out = self.bn(out)
        out = F.relu(out)
        out = self.pointwise(out)
        return out

class MultiDilationSeparableConv2d(nn.Module):
    """Multi-dilation separable conv - ì„±ëŠ¥ í•µì‹¬ ëª¨ë“ˆ"""
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=True):
        super().__init__()
        padding2 = padding + (dilation - 1) * (kernel_size - 1) // 2
        self.depthwise1 = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding,         1, groups=in_channels, bias=False)
        self.depthwise2 = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding2, dilation, groups=in_channels, bias=False)
        self.pointwise  = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)
        self.bn1 = nn.BatchNorm2d(in_channels, eps=1e-3)
        self.bn2 = nn.BatchNorm2d(in_channels, eps=1e-3)

    def forward(self, x):
        x1 = self.depthwise1(x)
        x1 = self.bn1(x1)
        x1 = F.relu(x1)

        x2 = self.depthwise2(x)
        x2 = self.bn2(x2)
        x2 = F.relu(x2)

        out = x1 + x2
        out = self.pointwise(out)
        return out

class LightweightChannelAttention(nn.Module):
    """ê²½ëŸ‰ Channel Attention - ì„±ëŠ¥ í–¥ìƒì˜ í•µì‹¬"""
    def __init__(self, channels, reduction=4):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        
        # ë§¤ìš° ê²½ëŸ‰í•œ FC layers
        self.fc = nn.Sequential(
            nn.Conv2d(channels, channels // reduction, 1, bias=False),
            nn.ReLU(inplace=True),
            nn.Conv2d(channels // reduction, channels, 1, bias=False)
        )
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        attention = self.sigmoid(avg_out + max_out)
        return x * attention

class EnhancedMultiScaleModule(nn.Module):
    """í–¥ìƒëœ Multi-scale ëª¨ë“ˆ - VOC ì„±ëŠ¥ ê°œì„ """
    def __init__(self, in_channels, out_channels):
        super().__init__()
        mid_channels = in_channels // 4
        
        # ë” ë‹¤ì–‘í•œ scale branches (VOCì˜ ë‹¤ì–‘í•œ ê°ì²´ í¬ê¸° ëŒ€ì‘)
        self.branch1 = SeparableConv2d(in_channels, mid_channels, 3, padding=1, dilation=1)
        self.branch2 = SeparableConv2d(in_channels, mid_channels, 3, padding=2, dilation=2)
        self.branch3 = SeparableConv2d(in_channels, mid_channels, 3, padding=4, dilation=4)
        self.branch4 = SeparableConv2d(in_channels, mid_channels, 3, padding=6, dilation=6)
        
        # Global context branch
        self.global_branch = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(in_channels, mid_channels, 1, bias=False),
            nn.BatchNorm2d(mid_channels, eps=1e-3),
            nn.ReLU(inplace=True)
        )
        
        # Feature fusion with attention
        self.fusion = nn.Sequential(
            nn.Conv2d(mid_channels * 5, out_channels, kernel_size=1, bias=False),
            nn.BatchNorm2d(out_channels, eps=1e-3),
            nn.ReLU(inplace=True)
        )
        
        # Channel attention for fusion
        self.attention = LightweightChannelAttention(out_channels)
        
    def forward(self, x):
        b1 = self.branch1(x)
        b2 = self.branch2(x)
        b3 = self.branch3(x)
        b4 = self.branch4(x)
        
        # Global context
        bg = self.global_branch(x)
        bg = F.interpolate(bg, size=x.shape[2:], mode='bilinear', align_corners=True)
        
        # Fusion
        fused = torch.cat([b1, b2, b3, b4, bg], dim=1)
        out = self.fusion(fused)
        
        # Apply attention
        out = self.attention(out)
        
        return out

class MicroDownsampleModule(nn.Module):
    """ë‹¤ìš´ìƒ˜í”Œë§ ëª¨ë“ˆ - DenseNet ìŠ¤íƒ€ì¼"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.use_maxpool = in_channels < out_channels

        if not self.use_maxpool:
            channels_conv = out_channels
        else:
            channels_conv = out_channels - in_channels

        self.conv = nn.Conv2d(in_channels, channels_conv, kernel_size=3, stride=2, padding=1, dilation=1, bias=False)
        self.bn = nn.BatchNorm2d(out_channels, eps=1e-3)

    def forward(self, x):
        out = self.conv(x)

        if self.use_maxpool:
            x_pool = F.max_pool2d(x, kernel_size=2, stride=2)
            out = torch.cat([out, x_pool], dim=1)

        out = self.bn(out)
        return F.relu(out)

class MicroResidualConvModule(nn.Module):
    """Residual ëª¨ë“ˆ - í‘œí˜„ë ¥ ê°•í™”"""
    def __init__(self, channels, dilation, dropout=0):
        super().__init__()
        self.conv = SeparableConv2d(channels, channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False)
        self.bn = nn.BatchNorm2d(channels, eps=1e-3)
        self.dropout = nn.Dropout2d(dropout)

    def forward(self, x):
        out = self.conv(x)
        out = self.bn(out)
        out = self.dropout(out)
        return F.relu(x + out)

class MicroResidualMultiDilationConvModule(nn.Module):
    """Multi-dilation Residual ëª¨ë“ˆ - í•µì‹¬ ì„±ëŠ¥ ëª¨ë“ˆ"""
    def __init__(self, channels, dilation, dropout=0):
        super().__init__()
        self.conv = MultiDilationSeparableConv2d(channels, channels, kernel_size=3, stride=1, padding=1, dilation=dilation, bias=False)
        self.bn = nn.BatchNorm2d(channels, eps=1e-3)
        self.dropout = nn.Dropout2d(dropout)

    def forward(self, x):
        out = self.conv(x)
        out = self.bn(out)
        out = self.dropout(out)
        return F.relu(x + out)

class MicroUpsampleModule(nn.Module):
    """ì—…ìƒ˜í”Œë§ ëª¨ë“ˆ"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)
        self.bn = nn.BatchNorm2d(out_channels, eps=1e-3)

    def forward(self, x):
        out = self.conv(x)
        out = self.bn(out)
        return F.relu(out)

class FeaturePyramidFusion(nn.Module):
    """Feature Pyramid Network ìŠ¤íƒ€ì¼ fusion - VOC ì„±ëŠ¥ í–¥ìƒ"""
    def __init__(self, high_channels, low_channels, out_channels):
        super().__init__()
        # High-level feature processing
        self.high_conv = nn.Sequential(
            nn.Conv2d(high_channels, out_channels, 1, bias=False),
            nn.BatchNorm2d(out_channels, eps=1e-3),
            nn.ReLU(inplace=True)
        )
        
        # Low-level feature processing
        self.low_conv = nn.Sequential(
            nn.Conv2d(low_channels, out_channels, 1, bias=False),
            nn.BatchNorm2d(out_channels, eps=1e-3),
            nn.ReLU(inplace=True)
        )
        
        # Final fusion
        self.fusion_conv = nn.Sequential(
            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels, eps=1e-3),
            nn.ReLU(inplace=True)
        )

    def forward(self, high_feat, low_feat):
        # Process high-level features
        high_processed = self.high_conv(high_feat)
        
        # Upsample to match low-level feature size
        high_upsampled = F.interpolate(high_processed, size=low_feat.shape[2:], mode='bilinear', align_corners=True)
        
        # Process low-level features
        low_processed = self.low_conv(low_feat)
        
        # Element-wise addition
        fused = high_upsampled + low_processed
        
        # Final convolution
        out = self.fusion_conv(fused)
        
        return out

# --- MicroNetv6 ì¸ì½”ë” (ì„±ëŠ¥ í–¥ìƒ) ---

class MicroNetV6Encoder(nn.Module):
    """MicroNetv6 ì¸ì½”ë” - ì„±ëŠ¥ í–¥ìƒ + í˜ì‹ ì  ê¸°ìˆ """
    def __init__(self, in_channels):
        super().__init__()

        # ì±„ë„ ìˆ˜: 3 â†’ 10 â†’ 20 â†’ 28 (v5: 26ì—ì„œ ì•½ê°„ ì¦ê°€)
        self.downsample_1 = MicroDownsampleModule(in_channels, 10)
        self.downsample_2 = MicroDownsampleModule(10, 20)
        
        # Downsample modules: 2ê°œ ìœ ì§€
        self.downsample_modules = nn.Sequential(*[
            MicroResidualConvModule(20, 1, 0),
            MicroResidualConvModule(20, 1, 0)
        ])
        
        self.downsample_3 = MicroDownsampleModule(20, 28)

        # Enhanced feature modules: 5ê°œë¡œ ì¦ê°€ (ë” ë‹¤ì–‘í•œ receptive field)
        rates = [1, 2, 4, 6, 8]  # vs v5: [1, 2, 4, 8]
        self.feature_modules = nn.Sequential(*[
            MicroResidualMultiDilationConvModule(28, rate, 0.1) for rate in rates
        ])
        
        # Enhanced multi-scale module
        self.multi_scale = EnhancedMultiScaleModule(28, 28)

    def forward(self, x):
        d1 = self.downsample_1(x)
        d2 = self.downsample_2(d1)
        m2 = self.downsample_modules(d2)
        d3 = self.downsample_3(m2)
        m4 = self.feature_modules(d3)
        
        # Enhanced multi-scale processing
        m4_enhanced = self.multi_scale(m4)
        
        return m4_enhanced, d2, d1  # ë” ë§ì€ skip connections

# --- ìµœì¢… ì œì¶œ ëª¨ë¸: MicroNetv6 (ì„±ëŠ¥ í–¥ìƒ) ---
class submission_MicroNetv6(nn.Module):
    """MicroNetv6 - ì„±ëŠ¥ í–¥ìƒ + í˜ì‹ ì  ê¸°ìˆ  ë„ì…"""
    def __init__(self, in_channels, num_classes, interpolate=True):
        super().__init__()

        self.interpolate = interpolate

        # ì¸ì½”ë” (ì„±ëŠ¥ í–¥ìƒ)
        self.encoder = MicroNetV6Encoder(in_channels)

        # Enhanced auxiliary path
        self.aux_downsample = MicroDownsampleModule(in_channels, 10)
        self.aux_refine = nn.Sequential(
            MicroResidualConvModule(10, 1, 0),
            LightweightChannelAttention(10)  # Attention ì¶”ê°€
        )

        # Feature Pyramid Network ìŠ¤íƒ€ì¼ decoder
        self.fpn_fusion1 = FeaturePyramidFusion(28, 20, 20)  # high_feat(28) + skip(20) â†’ 20
        self.fpn_fusion2 = FeaturePyramidFusion(20, 10, 12)  # fused(20) + aux(10) â†’ 12
        
        # Final upsample modules
        self.upsample_mods = nn.Sequential(*[
            MicroResidualConvModule(12, 1, 0),
            LightweightChannelAttention(12),  # Attention ì¶”ê°€
            MicroResidualConvModule(12, 1, 0)
        ])

        # ì¶œë ¥ (ê°œì„ )
        self.output_conv = nn.ConvTranspose2d(12, num_classes, kernel_size=3, stride=2, padding=1, output_padding=1, bias=True)

    def forward(self, x):
        # Auxiliary path (ì €ìˆ˜ì¤€ íŠ¹ì§• ë³´ì¡´)
        aux = self.aux_downsample(x)
        aux = self.aux_refine(aux)
        
        # Main encoder
        enc, skip2, skip1 = self.encoder(x)
        
        # Feature Pyramid Network ìŠ¤íƒ€ì¼ decoding
        # Stage 1: high-level(28) + mid-level(20) â†’ 20
        fused1 = self.fpn_fusion1(enc, skip2)
        
        # Stage 2: fused(20) + low-level(10) â†’ 12
        fused2 = self.fpn_fusion2(fused1, aux)
        
        # Final processing
        refined = self.upsample_mods(fused2)

        # Output
        out = self.output_conv(refined)

        if self.interpolate:
            out = F.interpolate(out, size=x.shape[2:], mode='bilinear', align_corners=True)

        return out

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ë° íŒŒë¼ë¯¸í„° ê²€ì¦
    num_classes = 21
    net = submission_MicroNetv6(in_channels=3, num_classes=num_classes)
    p = sum(p.numel() for p in net.parameters() if p.requires_grad)
    print(f"Model: MicroNetv6 (ì„±ëŠ¥ í–¥ìƒ + í˜ì‹ ì  ê¸°ìˆ )")
    print(f"Trainable Params: {p:,} ({p/1e3:.2f} K)")
    
    # íŒŒë¼ë¯¸í„° ëª©í‘œ ê²€ì¦
    if p <= 15000:
        print(f"âœ… v5 ìˆ˜ì¤€ ìœ ì§€: {p}/15,000")
    elif p <= 20000:
        print(f"âœ… ëª©í‘œ ë‹¬ì„±: {p}/20,000 ({20000-p} ì—¬ìœ )")
    elif p <= 25000:
        print(f"âœ… í—ˆìš© ë²”ìœ„: {p}/25,000 ({25000-p} ì—¬ìœ )")
    else:
        print(f"âš ï¸  ëª©í‘œ ì´ˆê³¼: {p}/20,000 ({p-20000} ì´ˆê³¼)")

    try:
        net.eval()  # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
        x = torch.randn(1, 3, 256, 256)
        y = net(x)
        print(f"Input shape: {x.shape}")
        print(f"Output shape: {y.shape}")
        assert y.shape == (1, num_classes, 256, 256)
        print("âœ… ëª¨ë¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ í†µê³¼")
        
        # ë‹¤ì–‘í•œ í´ë˜ìŠ¤ ìˆ˜ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸
        for nc in [1, 2, 21]:
            net_test = submission_MicroNetv6(in_channels=3, num_classes=nc)
            net_test.eval()
            y_test = net_test(x)
            assert y_test.shape == (1, nc, 256, 256)
            print(f"âœ… {nc} í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸ í†µê³¼")
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
    # ì´ì „ ë²„ì „ë“¤ê³¼ ë¹„êµ ë¶„ì„
    print(f"\nğŸ“Š ëª¨ë¸ ì§„í™” ë¶„ì„:")
    print(f"  MicroNetv2: 15,459ê°œ â†’ 0.4085 IoU")
    print(f"  MicroNetv4: 28,965ê°œ â†’ 0.4046 IoU (ë¹„íš¨ìœ¨)")
    print(f"  MicroNetv5: 15,461ê°œ â†’ 0.4247 IoU (íš¨ìœ¨ì )")
    print(f"  MicroNetv6: {p:,}ê°œ â†’ ëª©í‘œ: 0.43+ IoU (í˜ì‹ )")
    
    # ëª¨ë“ˆë³„ íŒŒë¼ë¯¸í„° ë¶„ì„
    encoder_params = sum(p.numel() for p in net.encoder.parameters())
    aux_params = sum(p.numel() for p in net.aux_downsample.parameters()) + sum(p.numel() for p in net.aux_refine.parameters())
    fpn_params = sum(p.numel() for p in net.fpn_fusion1.parameters()) + sum(p.numel() for p in net.fpn_fusion2.parameters())
    upsample_params = sum(p.numel() for p in net.upsample_mods.parameters())
    output_params = sum(p.numel() for p in net.output_conv.parameters())
    
    print(f"\nğŸ¯ ëª¨ë“ˆë³„ íŒŒë¼ë¯¸í„° ë¶„ë°°:")
    print(f"  Encoder: {encoder_params:,} ({encoder_params/p*100:.1f}%)")
    print(f"  Auxiliary: {aux_params:,} ({aux_params/p*100:.1f}%)")
    print(f"  FPN Fusion: {fpn_params:,} ({fpn_params/p*100:.1f}%)")
    print(f"  Upsample: {upsample_params:,} ({upsample_params/p*100:.1f}%)")
    print(f"  Output: {output_params:,} ({output_params/p*100:.1f}%)")
    
    print(f"\nğŸš€ MicroNetv6 í˜ì‹ ì  ê¸°ìˆ :")
    print(f"  ğŸ†• LightweightChannelAttention - íš¨ìœ¨ì  attention")
    print(f"  ğŸ†• EnhancedMultiScaleModule - VOC ì„±ëŠ¥ í–¥ìƒ")
    print(f"  ğŸ†• FeaturePyramidFusion - FPN ìŠ¤íƒ€ì¼ decoder")
    print(f"  âœ… 5ê°œ feature modules (rates: 1,2,4,6,8)")
    print(f"  âœ… ë‹¤ì¤‘ skip connections + attention")
    
    print(f"\nğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ :")
    print(f"  ì „ì²´ ì„±ëŠ¥: 0.4247 â†’ 0.43+ IoU")
    print(f"  VOC ì„±ëŠ¥: 0.1301 â†’ 0.15+ IoU (í•µì‹¬ ëª©í‘œ)")
    print(f"  Multi-class ëŒ€ì‘: Enhanced multi-scaleë¡œ ê°œì„ ")
    print(f"  Feature fusion: FPNìœ¼ë¡œ ì •ë³´ ì†ì‹¤ ìµœì†Œí™”")
    
    print(f"\nğŸ” í•µì‹¬ ê°œì„  í¬ì¸íŠ¸:")
    print(f"  ğŸ¯ VOC íŠ¹í™”: ë‹¤ì–‘í•œ ê°ì²´ í¬ê¸° ëŒ€ì‘ (1,2,4,6,8 dilation)")
    print(f"  ğŸ¯ Attention ë„ì…: Channel attentionìœ¼ë¡œ ì¤‘ìš” íŠ¹ì§• ê°•ì¡°")
    print(f"  ğŸ¯ FPN êµ¬ì¡°: ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì •ë³´ íš¨ê³¼ì  ìœµí•©")
    print(f"  ğŸ¯ Global context: AdaptiveAvgPoolë¡œ ì „ì—­ ì •ë³´ í™œìš©")
    
    print(f"\nâœ¨ MicroNetv6 ì„¤ê³„ ì² í•™:")
    print(f"  ğŸš€ ì„±ëŠ¥ ìš°ì„ : v5 ê¸°ë°˜ìœ¼ë¡œ í˜ì‹ ì  ê¸°ìˆ  ë„ì…")
    print(f"  ğŸ¯ VOC ì§‘ì¤‘: ê°€ì¥ ì–´ë ¤ìš´ ë°ì´í„°ì…‹ ì„±ëŠ¥ í–¥ìƒ")
    print(f"  âš¡ íš¨ìœ¨ì  í˜ì‹ : íŒŒë¼ë¯¸í„° ì¦ê°€ ìµœì†Œí™”í•˜ë©° ì„±ëŠ¥ ê·¹ëŒ€í™”")
    print(f"  ğŸ”§ ê²€ì¦ëœ + ìƒˆë¡œìš´: ì•ˆì •ì  êµ¬ì¡°ì— í˜ì‹  ê¸°ìˆ  ê²°í•©")
    
    # ê¸°ìˆ ì  í˜ì‹  ìš”ì•½
    print(f"\nğŸ”¬ ê¸°ìˆ ì  í˜ì‹  ìš”ì•½:")
    print(f"  Channel Attention: ì¤‘ìš” ì±„ë„ ê°•ì¡°ë¡œ í‘œí˜„ë ¥ í–¥ìƒ")
    print(f"  Multi-scale Enhancement: 5ê°œ branch + global context")
    print(f"  Feature Pyramid: ê³„ì¸µì  íŠ¹ì§• ìœµí•©ìœ¼ë¡œ ì •ë³´ ë³´ì¡´")
    print(f"  Adaptive Fusion: ë°ì´í„°ì…‹ë³„ íŠ¹ì„± ê³ ë ¤í•œ ìœµí•©")
    
    print(f"\nğŸ¯ ì„±ëŠ¥ ì˜ˆì¸¡:")
    print(f"  VOC: 0.1301 â†’ 0.15+ (ë‹¤ì¤‘ í´ë˜ìŠ¤ ëŒ€ì‘ ê°•í™”)")
    print(f"  ETIS: 0.3713 â†’ 0.38+ (attention íš¨ê³¼)")
    print(f"  CVPPP: 0.9209 â†’ 0.92+ (ì´ë¯¸ ë†’ì€ ìˆ˜ì¤€ ìœ ì§€)")
    print(f"  CFD: 0.3205 â†’ 0.34+ (multi-scale íš¨ê³¼)")
    print(f"  CarDD: 0.3806 â†’ 0.39+ (feature fusion íš¨ê³¼)")
    print(f"  ì „ì²´: 0.4247 â†’ 0.43+ IoU ëª©í‘œ") 