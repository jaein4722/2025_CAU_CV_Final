import torch
import torch.nn as nn
import torch.nn.functional as F

# --- MicroNetv12_Balanced: 8K íŒŒë¼ë¯¸í„° ê· í˜•ì¡íŒ ì„¤ê³„ ---

class SeparableConv2d(nn.Module):
    """Depthwise separable convolution - í•µì‹¬ íš¨ìœ¨ ëª¨ë“ˆ"""
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=False):
        super().__init__()
        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels, bias=False)
        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)
        self.bn = nn.BatchNorm2d(in_channels, eps=1e-3)

    def forward(self, x):
        out = self.depthwise(x)
        out = self.bn(out)
        out = F.relu(out)
        out = self.pointwise(out)
        return out

class MultiDilationSeparableConv2d(nn.Module):
    """Multi-dilation separable conv - ì„±ëŠ¥ í•µì‹¬ ëª¨ë“ˆ (ìœ ì§€)"""
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=False):
        super().__init__()
        padding2 = padding + (dilation - 1) * (kernel_size - 1) // 2
        self.depthwise1 = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding,         1, groups=in_channels, bias=False)
        self.depthwise2 = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding2, dilation, groups=in_channels, bias=False)
        self.pointwise  = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)
        self.bn1 = nn.BatchNorm2d(in_channels, eps=1e-3)
        self.bn2 = nn.BatchNorm2d(in_channels, eps=1e-3)

    def forward(self, x):
        x1 = self.depthwise1(x)
        x1 = self.bn1(x1)
        x1 = F.relu(x1)

        x2 = self.depthwise2(x)
        x2 = self.bn2(x2)
        x2 = F.relu(x2)

        out = x1 + x2
        out = self.pointwise(out)
        return out

class BalancedCFDModule(nn.Module):
    """ê· í˜•ì¡íŒ CFD ëª¨ë“ˆ - íš¨ìœ¨ì  CFD ì²˜ë¦¬ (Separable Conv ì‚¬ìš©)"""
    def __init__(self, channels):
        super().__init__()
        # 2ë‹¨ê³„ processing (Separable Convë¡œ íŒŒë¼ë¯¸í„° ì ˆì•½)
        self.fine_conv1 = SeparableConv2d(channels, channels, kernel_size=3, padding=1, bias=False)
        self.fine_conv2 = nn.Conv2d(channels, channels, kernel_size=1, bias=False)  # 1x1ì€ ê·¸ëŒ€ë¡œ
        
        self.bn = nn.BatchNorm2d(channels, eps=1e-3)
        
        # CFD íŠ¹í™” stabilization
        self.dropout = nn.Dropout2d(0.05)

    def forward(self, x):
        out1 = self.fine_conv1(x)
        out1 = F.relu(out1)
        
        out2 = self.fine_conv2(out1)
        out2 = self.bn(out2)
        out2 = self.dropout(out2)
        
        return F.relu(x + out2)

class BalancedMedicalModule(nn.Module):
    """ê· í˜•ì¡íŒ Medical ëª¨ë“ˆ - íš¨ìœ¨ì  ETIS ì²˜ë¦¬ (Separable Conv ì‚¬ìš©)"""
    def __init__(self, channels):
        super().__init__()
        # ë‹¨ì¼ ë‹¨ê³„ edge enhancement (Separable Convë¡œ íŒŒë¼ë¯¸í„° ì ˆì•½)
        self.edge_conv = SeparableConv2d(channels, channels, kernel_size=3, padding=1, bias=False)
        self.dropout = nn.Dropout2d(0.03)

    def forward(self, x):
        edge = self.edge_conv(x)
        edge = self.dropout(edge)
        return F.relu(x + edge)

class BalancedMultiScaleModule(nn.Module):
    """ê· í˜•ì¡íŒ Multi-scale ëª¨ë“ˆ - 2-branch íš¨ìœ¨ì  (Separable Conv ì‚¬ìš©)"""
    def __init__(self, channels):
        super().__init__()
        # 2-branchë¡œ íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± ìœ ì§€
        half_channels = channels // 2
        self.branch1 = nn.Conv2d(channels, half_channels, kernel_size=1, bias=False)  # 1x1ì€ ê·¸ëŒ€ë¡œ
        self.branch2 = SeparableConv2d(channels, half_channels, kernel_size=3, padding=2, dilation=2, bias=False)
        
        # Fusionë„ ê°„ì†Œí™”
        self.fusion = nn.Conv2d(channels, channels, kernel_size=1, bias=False)
        self.bn = nn.BatchNorm2d(channels, eps=1e-3)

    def forward(self, x):
        b1 = self.branch1(x)
        b2 = self.branch2(x)
        
        concat = torch.cat([b1, b2], dim=1)
        out = self.fusion(concat)
        out = self.bn(out)
        return F.relu(x + out)

class CompactAttention(nn.Module):
    """ì»´íŒ©íŠ¸ Attention ëª¨ë“ˆ - ìµœì†Œ íŒŒë¼ë¯¸í„°"""
    def __init__(self, channels):
        super().__init__()
        # ë§¤ìš° ê²½ëŸ‰ channel attention
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Conv2d(channels, max(channels // 8, 1), kernel_size=1, bias=False),
            nn.ReLU(),
            nn.Conv2d(max(channels // 8, 1), channels, kernel_size=1, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        att = self.avg_pool(x)
        att = self.fc(att)
        return x * att

class MicroDownsampleModule(nn.Module):
    """ë‹¤ìš´ìƒ˜í”Œë§ ëª¨ë“ˆ - DenseNet ìŠ¤íƒ€ì¼ (ìœ ì§€)"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.use_maxpool = in_channels < out_channels

        if not self.use_maxpool:
            channels_conv = out_channels
        else:
            channels_conv = out_channels - in_channels

        self.conv = nn.Conv2d(in_channels, channels_conv, kernel_size=3, stride=2, padding=1, dilation=1, bias=False)
        self.bn = nn.BatchNorm2d(out_channels, eps=1e-3)

    def forward(self, x):
        out = self.conv(x)

        if self.use_maxpool:
            x_pool = F.max_pool2d(x, kernel_size=2, stride=2)
            out = torch.cat([out, x_pool], dim=1)

        out = self.bn(out)
        return F.relu(out)

class MicroResidualMultiDilationConvModule(nn.Module):
    """Multi-dilation Residual ëª¨ë“ˆ - í•µì‹¬ ì„±ëŠ¥ ëª¨ë“ˆ (ìœ ì§€)"""
    def __init__(self, channels, dilation, dropout=0):
        super().__init__()
        self.conv = MultiDilationSeparableConv2d(channels, channels, kernel_size=3, stride=1, padding=1, dilation=dilation, bias=False)
        self.bn = nn.BatchNorm2d(channels, eps=1e-3)
        self.dropout = nn.Dropout2d(dropout)

    def forward(self, x):
        out = self.conv(x)
        out = self.bn(out)
        out = self.dropout(out)
        return F.relu(x + out)

class MicroUpsampleModule(nn.Module):
    """ì—…ìƒ˜í”Œë§ ëª¨ë“ˆ"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)
        self.bn = nn.BatchNorm2d(out_channels, eps=1e-3)

    def forward(self, x):
        out = self.conv(x)
        out = self.bn(out)
        return F.relu(out)

# --- MicroNetv12_Balanced ì¸ì½”ë” ---

class MicroNetV12BalancedEncoder(nn.Module):
    """MicroNetv12_Balanced ì¸ì½”ë” - ê· í˜•ì¡íŒ ì„¤ê³„"""
    def __init__(self, in_channels):
        super().__init__()

        # ê²½ëŸ‰í™”ëœ ì±„ë„: 3 â†’ 7 â†’ 12 â†’ 15
        self.downsample_1 = MicroDownsampleModule(in_channels, 7)
        self.downsample_2 = MicroDownsampleModule(7, 12)
        
        # ê· í˜•ì¡íŒ ëª¨ë“ˆ ì‹œìŠ¤í…œ
        self.downsample_modules = nn.Sequential(
            BalancedCFDModule(12),
            BalancedMedicalModule(12),
            BalancedMultiScaleModule(12)
        )
        
        self.downsample_3 = MicroDownsampleModule(12, 15)

        # ì»´íŒ©íŠ¸ Attention
        self.attention = CompactAttention(15)

        # Feature modules: 2ê°œë¡œ ì¶•ì†Œ (rates: 1,2)
        rates = [1, 2]
        self.feature_modules = nn.Sequential(*[
            MicroResidualMultiDilationConvModule(15, rate, 0.08) for rate in rates
        ])

    def forward(self, x):
        d1 = self.downsample_1(x)
        d2 = self.downsample_2(d1)
        m2 = self.downsample_modules(d2)
        d3 = self.downsample_3(m2)
        
        # Attention ì ìš©
        d3 = self.attention(d3)
        
        m4 = self.feature_modules(d3)
        
        return m4, d2  # skip connection

# --- ìµœì¢… ì œì¶œ ëª¨ë¸: MicroNetv12_Balanced ---
class submission_MicroNetv12_balanced(nn.Module):
    """MicroNetv12_Balanced - 8K íŒŒë¼ë¯¸í„° ê· í˜•ì¡íŒ ì„¤ê³„"""
    def __init__(self, in_channels, num_classes, interpolate=True):
        super().__init__()

        self.interpolate = interpolate

        # ì¸ì½”ë” (ê· í˜•ì¡íŒ)
        self.encoder = MicroNetV12BalancedEncoder(in_channels)

        # ê²½ëŸ‰í™”ëœ Auxiliary path
        self.aux_downsample = MicroDownsampleModule(in_channels, 7)
        self.aux_refine = BalancedCFDModule(7)

        # ê²½ëŸ‰í™”ëœ ì—…ìƒ˜í”Œ ë¸”ë¡
        self.upsample_1 = MicroUpsampleModule(15, 12)
        
        # ê²½ëŸ‰í™”ëœ processing
        self.upsample_mods = nn.Sequential(
            BalancedCFDModule(12),
            BalancedMultiScaleModule(12)
        )

        # ì¶œë ¥ (bias=Falseë¡œ íŒŒë¼ë¯¸í„° ì ˆì•½)
        self.output_conv = nn.ConvTranspose2d(12, num_classes, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)

    def forward(self, x):
        # Auxiliary path (ì €ìˆ˜ì¤€ íŠ¹ì§• ë³´ì¡´)
        aux = self.aux_downsample(x)
        aux = self.aux_refine(aux)
        
        # Main encoder
        enc, skip = self.encoder(x)
        
        # ê· í˜•ì¡íŒ decoder
        up1 = self.upsample_1(enc)
        
        # Skip connection í™œìš© (ì±„ë„ ìˆ˜ ë§ì¶¤)
        if up1.shape[2:] == skip.shape[2:] and up1.shape[1] == skip.shape[1]:
            up1 = up1 + skip
        
        # ê· í˜•ì¡íŒ processing
        up1 = self.upsample_mods(up1)
        
        # Auxiliary pathì™€ ê²°í•© (ì±„ë„ ìˆ˜ ë§ì¶¤)
        if up1.shape[2:] == aux.shape[2:] and up1.shape[1] == aux.shape[1]:
            up1 = up1 + aux
        
        # ìµœì¢… ì¶œë ¥
        output = self.output_conv(up1)
        
        if self.interpolate and output.shape[2:] != x.shape[2:]:
            output = F.interpolate(output, size=x.shape[2:], mode='bilinear', align_corners=False)
        
        return output

    def count_parameters(self):
        """íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°"""
        return sum(p.numel() for p in self.parameters() if p.requires_grad)

# íŒŒë¼ë¯¸í„° ìˆ˜ í™•ì¸ìš©
if __name__ == "__main__":
    # VOC ê¸°ì¤€ í…ŒìŠ¤íŠ¸ (21 í´ë˜ìŠ¤)
    model_voc = submission_MicroNetv12_balanced(3, 21)
    params_voc = model_voc.count_parameters()
    print(f"VOC (21 classes) parameters: {params_voc:,}")
    
    # Binary ê¸°ì¤€ í…ŒìŠ¤íŠ¸ (2 í´ë˜ìŠ¤)
    model_binary = submission_MicroNetv12_balanced(3, 2)
    params_binary = model_binary.count_parameters()
    print(f"Binary (2 classes) parameters: {params_binary:,}")
    
    # ëª©í‘œ ëŒ€ë¹„ ë¶„ì„
    target_min, target_max = 7000, 9000
    if target_min <= params_voc <= target_max:
        print(f'âœ… ëª©í‘œ ë‹¬ì„±! ({target_min:,}~{target_max:,}ê°œ ë²”ìœ„)')
    elif params_voc < target_min:
        print(f'âš ï¸ ëª©í‘œ ë¯¸ë‹¬ ({target_min - params_voc:,}ê°œ ë¶€ì¡±)')
    else:
        print(f'âŒ ëª©í‘œ ì´ˆê³¼ ({params_voc - target_max:,}ê°œ ì´ˆê³¼)')
    
    # í…ŒìŠ¤íŠ¸
    x = torch.randn(1, 3, 256, 256)
    try:
        y = model_voc(x)
        print(f"âœ… ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {x.shape} â†’ {y.shape}")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    print(f"\nâš–ï¸ ê· í˜•ì¡íŒ ì „ëµ:")
    print(f"v11_ultra: 4,062ê°œ â†’ v12_balanced: {params_voc:,}ê°œ")
    print(f"ì¦ê°€ëŸ‰: {params_voc - 4062:,}ê°œ ({(params_voc - 4062)/4062*100:.1f}% ì¦ê°€)")
    print(f"v12 ëŒ€ë¹„: 31,030ê°œ â†’ {params_voc:,}ê°œ ({(31030 - params_voc)/31030*100:.1f}% ê°ì†Œ)")
    
    print(f"\nğŸ¯ ì„±ëŠ¥ ëª©í‘œ:")
    print(f"- Mean IoU: 0.40+ (v11_ultra 0.3439 ëŒ€ë¹„ 16% í–¥ìƒ)")
    print(f"- CFD IoU: 0.40+ (Balanced CFD ëª¨ë“ˆ)")
    print(f"- ETIS IoU: 0.40+ (Balanced Medical ëª¨ë“ˆ)")
    print(f"- CarDD IoU: 0.40+ (Balanced Multi-scale)")
    
    print(f"\nğŸ”§ ê· í˜•ì¡íŒ í˜ì‹ :")
    print(f"- Balanced CFD ëª¨ë“ˆ (íš¨ìœ¨ì )")
    print(f"- Balanced Medical ëª¨ë“ˆ (ETIS ì§‘ì¤‘)")
    print(f"- Balanced Multi-scale (2-branch)")
    print(f"- Compact Attention (ìµœì†Œ íŒŒë¼ë¯¸í„°)")
    print(f"- 3ê°œ Feature modules (rates: 1,2,4)")
    print(f"- ê· í˜•ì¡íŒ ì±„ë„ (8â†’14â†’18)") 