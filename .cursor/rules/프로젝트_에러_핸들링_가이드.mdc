---
description: 
globs: 
alwaysApply: true
---
# 🛠️ 프로젝트 에러 핸들링 가이드

> **목적**: 다음 작업자가 반복 가능한 실수를 방지하고 효율적인 개발을 돕기 위한 가이드  
> **업데이트**: 2025년 6월 15일  
> **기반**: 83회 실험에서 발생한 실제 에러들 및 해결 방법

---

## 🚨 1. 최우선 확인사항 (실험 시작 전 필수)

### 1.1 파라미터 수 제한 확인 ⚠️
```python
# 모델 생성 후 반드시 파라미터 수 확인
model = YourModel(in_channels=3, num_classes=21)
total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"Total trainable parameters: {total_params:,}")

# 제한 확인
assert total_params <= 10_000, f"Parameter limit exceeded: {total_params} > 10,000"
```

**❌ 흔한 실수**: 3 million 제한으로 착각하기  
**✅ 정답**: **10,000개** 파라미터 제한

### 1.2 모델 클래스명 확인
```python
# 최종 제출 모델의 클래스명은 반드시 다음과 같아야 함
class submission_20221555(nn.Module):
    def __init__(self, in_channels, num_classes):
        super().__init__()
        # 모델 구현
```

**❌ 흔한 실수**: 다른 클래스명 사용 (MicroNet, HWNet 등)  
**✅ 정답**: `submission_20221555` 고정

---

## 🔧 2. 모델 개발 시 주의사항

### 2.1 새 모델 생성 vs 기존 모델 수정

#### 🆕 새 모델 실험 시 (권장)
```python
# 새 파일 생성: models/submission_20221555/submission_ModelNamev2.py
class submission_ModelNamev2(nn.Module):
    def __init__(self, in_channels, num_classes):
        # 새로운 아키텍처 실험
```

**✅ 장점**: 이전 버전과 비교 가능, 롤백 용이  
**✅ 사용 시기**: 아키텍처 변경, 새로운 실험

#### 🔄 기존 모델 수정 시
```python
# 같은 파일에서 수정: models/submission_20221555/submission_ModelName.py
# 버그 수정, 하이퍼파라미터 조정 등
```

**✅ 사용 시기**: 버그 수정, 작은 조정  
**❌ 피할 상황**: 대규모 아키텍처 변경

### 2.2 파라미터 계산 실수 방지

#### 계산 도구 활용
```python
from torchsummary import summary

# 모델 요약 정보로 파라미터 확인
model = YourModel(3, 21)
summary(model, (3, 256, 256))
```

#### 수동 계산 검증
```python
def count_parameters(model):
    """정확한 파라미터 수 계산"""
    total = 0
    for name, param in model.named_parameters():
        if param.requires_grad:
            params = param.numel()
            print(f"{name}: {params:,}")
            total += params
    return total

total_params = count_parameters(model)
print(f"Total: {total_params:,}")
```

---

## 🐛 3. 자주 발생하는 에러와 해결법

### 3.1 RuntimeError: size mismatch
```python
# 에러 예시
RuntimeError: size mismatch, m1: [16 x 2048], m2: [1024 x 256]

# 원인: Adaptive pooling 후 차원 불일치
# 해결법: 디버그 출력 추가
def forward(self, x):
    x = self.encoder(x)
    print(f"After encoder: {x.shape}")  # 디버그
    x = self.adaptive_pool(x)
    print(f"After pooling: {x.shape}")  # 디버그
    # ...
```

**✅ 해결책**: 각 단계별 텐서 크기 확인 후 차원 조정

### 3.2 CUDA out of memory
```python
# 에러 상황: GPU 메모리 부족
RuntimeError: CUDA out of memory

# 해결법 1: 배치 크기 확인 (고정값 16 사용 중인지)
# 해결법 2: 모델 크기 줄이기
# 해결법 3: GPU 메모리 정리
torch.cuda.empty_cache()
```

**❌ 피해야 할 행동**: 배치 크기 임의 변경 (16 고정)  
**✅ 올바른 접근**: 모델 복잡도 줄이기

### 3.3 훈련이 수렴하지 않는 경우
```python
# 증상: Loss가 감소하지 않거나 NaN 발생

# 체크리스트:
1. 스케줄러 확인 (WarmupCosineLR 사용 권장)
2. 학습률 적정성 (0.01 권장)
3. Gradient clipping 필요성
4. 배치 정규화 위치
```

**✅ 검증된 설정**:
```python
# training_args.py
optimizer = AdamW(lr=0.01, weight_decay=0.0001)
scheduler = WarmupCosineLR(T_max=50, warmup=5)
```

---

## ⚡ 4. 성능 최적화 팁

### 4.1 파라미터 효율성 극대화
```python
# ✅ 권장: Depthwise Separable Convolution
nn.Conv2d(in_channels, in_channels, 3, groups=in_channels, padding=1),  # Depthwise
nn.Conv2d(in_channels, out_channels, 1)  # Pointwise

# ❌ 비권장: 일반 Convolution (파라미터 비효율적)
nn.Conv2d(in_channels, out_channels, 3, padding=1)
```

### 4.2 채널 분할 전략
```python
# HWNet 스타일 partial convolution
def partial_conv(x, ratio=0.5):
    c = x.size(1)
    c1 = int(c * ratio)
    x1, x2 = x[:, :c1], x[:, c1:]
    x1 = self.conv(x1)  # 일부만 연산
    return torch.cat([x1, x2], dim=1)
```

### 4.3 어텐션 메커니즘 경량화
```python
# ✅ UltraLight SE Attention
class UltraLightSE(nn.Module):
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.squeeze = nn.AdaptiveAvgPool2d(1)
        reduced_channels = max(1, channels // reduction)
        self.excitation = nn.Sequential(
            nn.Conv2d(channels, reduced_channels, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(reduced_channels, channels, 1),
            nn.Sigmoid()
        )
```

---

## 🔄 5. 실험 워크플로우 가이드

### 5.1 체계적 실험 진행
```
1. 기존 최고 성능 모델 분석
   ↓
2. 가설 설정 (어떤 개선을 시도할 것인가?)
   ↓
3. 파라미터 수 사전 계산
   ↓
4. 새 모델 파일 생성
   ↓
5. 기능 테스트 (Model_Test.ipynb)
   ↓
6. 훈련 실행 (competition_main.ipynb)
   ↓
7. 결과 분석 및 다음 실험 계획
```

### 5.2 실험 로깅
```python
# results.csv에 자동으로 기록되지만, 추가 메모 권장
experiment_notes = {
    "model_name": "MicroNetv14",
    "key_changes": "Added coordinate attention",
    "params": 8456,
    "hypothesis": "Spatial attention will improve edge detection"
}
```

---

## 🚑 6. 응급 상황 대처법

### 6.1 모델이 로드되지 않는 경우
```python
# 문제: 모델 클래스를 찾을 수 없음
ModuleNotFoundError: No module named 'submission_20221555'

# 해결책 1: __init__.py 파일 확인
# models/submission_20221555/__init__.py 존재하는지 확인

# 해결책 2: 클래스명 확인
# submission_20221555 클래스가 파일에 정의되어 있는지 확인
```

### 6.2 훈련 중 중단된 경우
```python
# 체크포인트에서 재시작 가능하지만, 
# 30 epochs 제한으로 인해 새로 시작하는 것이 일반적

# 빠른 디버깅을 위한 작은 데이터셋 테스트
python test_voc.py  # VOC 데이터셋만으로 빠른 테스트
```

### 6.3 Git 충돌 해결
```bash
# 실험 파일들이 많아서 Git 충돌 발생 시
git stash  # 현재 변경사항 임시 저장
git pull   # 최신 변경사항 가져오기
git stash pop  # 변경사항 다시 적용
```

---

## 📋 7. 실험 전 체크리스트

### 7.1 새 실험 시작 전 ✅
- [ ] 파라미터 수 ≤ 10,000 확인
- [ ] 모델 클래스명 `submission_20221555` 설정
- [ ] WarmupCosineLR 스케줄러 유지
- [ ] 새 파일명으로 버전 관리 (예: v14, v15...)
- [ ] 이전 최고 성능 모델 대비 개선점 명확히 정의

### 7.2 훈련 실행 전 ✅
- [ ] Model_Test.ipynb에서 기본 기능 테스트 통과
- [ ] GPU 메모리 충분한지 확인
- [ ] results.csv 백업 (실수로 덮어쓰기 방지)
- [ ] 실험 가설 및 예상 결과 메모

### 7.3 결과 분석 후 ✅
- [ ] results.csv에 결과 정상 기록되었는지 확인
- [ ] 이전 모델들과 성능 비교
- [ ] 실패 시 원인 분석 및 다음 실험 계획
- [ ] 성공 시 개선 요소 분석 및 추가 최적화 방향 설정

---

## 🎯 8. 최종 제출 전 검증 가이드

### 8.1 코드 검증
```python
# 1. 최종 모델 테스트
model = submission_20221555(3, 21)
assert sum(p.numel() for p in model.parameters() if p.requires_grad) <= 10000

# 2. 모든 데이터셋에서 forward pass 테스트
test_inputs = [
    torch.randn(1, 3, 256, 256),  # VOC (21 classes)
    torch.randn(1, 3, 256, 256),  # Binary datasets (2 classes)
]

for i, test_input in enumerate(test_inputs):
    num_classes = 21 if i == 0 else 2
    model = submission_20221555(3, num_classes)
    output = model(test_input)
    assert output.shape == (1, num_classes, 256, 256)
```

### 8.2 파일 정리
```
필수 파일들:
✅ models/submission_20221555/submission_최종모델.py
✅ training_args.py  
✅ requirements.txt (업데이트됨)
✅ README.md (선택사항이지만 권장)
```

---

## 🧠 9. 디버깅 마인드셋

### 9.1 에러 해결 접근법
1. **에러 메시지 정확히 읽기**: 스택 트레이스의 마지막 줄이 핵심
2. **단계별 디버깅**: 복잡한 모델을 간단한 버전으로 축소하여 테스트  
3. **검증된 코드 참고**: 이전에 성공한 모델들의 패턴 활용
4. **파라미터 추적**: 각 레이어별 파라미터 수 확인

### 9.2 성능 디버깅
```python
# 성능이 예상보다 낮을 때 체크할 것들:
1. 데이터 전처리 확인
2. 손실 함수 적절성
3. 학습률 및 스케줄러 설정
4. 모델 복잡도 vs 데이터 복잡도 균형
5. 배치 정규화 및 드롭아웃 위치
```

---

## 🎉 마무리 메시지

이 가이드는 **83번의 실험**에서 발생한 실제 에러들과 해결 과정을 기반으로 작성되었습니다. 

**기억하세요**:
- 🔴 **파라미터 제한 10,000개** - 절대 잊지 마세요!
- 🟡 **WarmupCosineLR 스케줄러** - 훈련 안정성의 핵심
- 🟢 **점진적 개선** - 큰 변화보다는 작은 개선들의 누적

모든 실패는 더 나은 모델로 가는 과정입니다. **포기하지 마시고 체계적으로 접근하세요!** 🚀

---

*"디버깅은 코드를 작성하는 것보다 두 배 어렵다. 따라서 코드를 작성할 때 최대한 영리하게 작성했다면, 정의상 그것을 디버깅할 만큼 영리하지 못하다." - Brian Kernighan*
