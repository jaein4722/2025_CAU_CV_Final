# 🎯 컴퓨터 비전 의미적 세그멘테이션 프로젝트 인수인계 문서

> **작성일**: 2025년 6월 15일  
> **대상**: 다음 작업자  
> **목적**: 프로젝트 전체 현황 파악 및 원활한 업무 인수인계

---

## 📋 1. 프로젝트 개요

### 1.1 목표
5개의 고정된 256×256 데이터셋에서 **단일 의미적 세그멘테이션 모델**을 처음부터 설계, 구현, 튜닝 및 평가

### 1.2 데이터셋 구성
| # | 데이터셋 | 도메인 | 클래스 수 | 분할 (train/val/test) |
|---|---------|--------|-----------|---------------------|
| 1 | Pascal VOC 2012 | 일반 | 21 | 1747 / 583 / 583 |
| 2 | ETIS-LaribPolypDB | 의료 | 2 | 118 / 39 / 39 |
| 3 | CVPPP2017-LSC | 식물 | 2 | 972 / 324 / 324 |
| 4 | CFD | 균열 | 2 | 70 / 24 / 24 |
| 5 | CarDD | 차량 손상 | 2 | 310 / 104 / 104 |

### 1.3 주요 제약사항 ⚠️
- **🔴 CRITICAL**: ≤ **10,000** 개의 훈련 가능한 파라미터 (실제 경쟁 제한)
- **사전 훈련된 가중치 사용 금지**
- **데이터 증강 기법 사용 금지**
- 고정된 훈련 루프: 30 epochs, batch size 16
- 모델 생성자는 반드시 `__init__(self, in_channels, num_classes)` 형태

### 1.4 평가 방식
- **주요 지표**: 5개 데이터셋의 평균 IoU
- **최종 점수**: 파라미터 수 순위 × 정확도 순위의 기하평균 × 32

---

## 📊 2. 현재 프로젝트 현황

### 2.1 실험 통계
- **총 실험 횟수**: 83회 (results.csv 기준)
- **최고 성능**: test 모델 (0.4333 IoU, 20,274 params)
- **최신 모델**: MicroNetv13 (0.3783 IoU, 6,937 params)
- **최경량 모델**: MicroNetv10_ultra (0.3194 IoU, 3,969 params)

### 2.2 성능 추이 분석
```
초기 실험 (Baseline): ~0.38 IoU (7.7M params) ❌ 제한 위반
중기 최적화: ~0.43 IoU (20k params) ✅ 제한 준수  
최신 극한 최적화: ~0.38 IoU (7k params) ✅ 제한 준수
```

---

## 🔬 3. 이전 작업자들의 실험 히스토리

### 3.1 1차 작업자 실험 (추정)
**주요 모델 시리즈**:
- **Baseline**: 기본 아키텍처 (7.7M params) - 제한 위반
- **ESPNet, LEDNet, SINet**: 경량 네트워크 실험
- **LCNet 시리즈**: 경량화 특화 네트워크 (508k params → 25k params)
- **MicroUNet 시리즈**: 극소형 U-Net 구조 (2k → 62k params)

**주요 성과**:
- LCNet_big: 0.4286 IoU (70,020 params)
- MicroUNet_Pro: 0.4300 IoU (581,515 params) - 제한 위반

### 3.2 2차 작업자 실험 (추정)  
**주요 모델 시리즈**:
- **HWNet 시리즈**: 하드웨어 효율적 네트워크
  - HWNetv3: **0.4457 IoU** (140,364 params) ⭐ 당시 최고 성능
  - HWNetNano_v2: 0.3966 IoU (8,342 params) ⭐ 경량화 최고
- **모듈화 개선**: Depthwise Separable Conv, 채널 분할 등

**핵심 발견**:
- **WarmupCosineLR 스케줄러**의 훈련 안정성 개선 효과 확인
- Parameter 효율성과 성능 간 트레이드오프 최적점 탐색

---

## 🚀 4. 현재 작업자(나)의 주요 기여사항

### 4.1 실험한 모델 시리즈
1. **HWNetUltra 시리즈** (v1~v5): HWNet 아키텍처 극한 최적화
2. **MiniNetv2**: 소형 네트워크 실험 (0.4729 IoU, 506k params)
3. **MicroNet 시리즈** (v1~v13): 초경량 네트워크 체계적 개발

### 4.2 주요 기술적 혁신 시도

#### 4.2.1 아키텍처 혁신
- **MorphGradientFocus**: 에지 향상을 위한 형태학적 그래디언트 적용
- **UltraLightSE**: 극경량 Squeeze-and-Excitation 어텐션
- **PCT (Partial Channel Transformation)**: 채널 분할 최적화
- **DWSConv**: Depthwise Separable Convolution으로 파라미터 효율성 향상

#### 4.2.2 훈련 최적화
- **WarmupCosineLR**: 학습률 웜업으로 훈련 안정성 확보
- **DiceCELoss + UniformCBCE_LovaszProb**: 다중 손실 함수 조합
- **AdamW 옵티마이저**: weight decay 정규화

#### 4.2.3 모델 설계 철학
- **점진적 복잡도 증가**: 단순한 구조에서 시작하여 점진적 개선
- **파라미터 예산 관리**: 10k 제한 내에서 최대 성능 추구
- **아키텍처 모듈화**: 재사용 가능한 컴포넌트 설계

### 4.3 주요 실험 결과

#### 최고 성능 모델들:
1. **test 모델**: 0.4333 IoU (20,274 params) - 전체 최고 성능
2. **MicroNetv5**: 0.4247 IoU (15,461 params) - 중간 파라미터 대역 최고
3. **MicroNetv4**: 0.4046 IoU (28,965 params) 

#### 경량화 성능 모델들:
1. **MicroNetv10_ultra**: 0.3194 IoU (3,969 params) - 4k 미만 최고
2. **MicroNetv11_ultra**: 0.3439 IoU (4,062 params)
3. **MicroNetv13**: 0.3783 IoU (6,937 params) - 최신 버전

### 4.4 실패한 시도들과 교훈

#### 4.4.1 아키텍처 관련
- **과도한 복잡화**: MicroNetv6-v7에서 너무 많은 기능 추가로 성능 저하
- **파라미터 불균형**: 인코더/디코더 간 파라미터 배분 최적화 필요
- **어텐션 오버헤드**: SE 어텐션의 효과 vs 파라미터 비용 트레이드오프

#### 4.4.2 훈련 관련  
- **학습률 조정**: 초기 높은 학습률로 인한 불안정성
- **배치 크기 제한**: 고정된 배치 크기 16으로 인한 최적화 제약
- **조기 종료**: 30 epochs 제한으로 인한 수렴 부족 가능성

---

## 💡 5. 핵심 인사이트 및 권장사항

### 5.1 아키텍처 설계 원칙
1. **채널 분할 활용**: HWNet 스타일의 partial convolution 효과적
2. **Depthwise Conv 필수**: 파라미터 효율성을 위한 핵심 기법
3. **다중 스케일 처리**: Dilated convolution으로 수용 영역 확장
4. **가벼운 어텐션**: SE보다 더 경량화된 어텐션 메커니즘 탐색 필요

### 5.2 파라미터 배분 전략
```
권장 파라미터 배분 (10k 기준):
- Encoder: 40-50% (4k-5k params)
- Decoder: 30-40% (3k-4k params)  
- Skip Connection/Attention: 10-20% (1k-2k params)
```

### 5.3 훈련 설정 최적화
- **스케줄러**: WarmupCosineLR (T_max=50, warmup=5) 고정 유지
- **옵티마이저**: AdamW (lr=0.01, weight_decay=0.0001)
- **손실 함수**: 이진 클래스용 DiceCELoss, 다중 클래스용 UniformCBCE_LovaszProb

---

## 🎯 6. 향후 개선 방향 제안

### 6.1 단기 개선 과제 (1-2일)
1. **MicroNetv13 기반 미세 조정**
   - 채널 수 최적화 (현재 C=8)
   - PCT 비율 조정 (현재 P=0.2)
   - 다중 스케일 dilated conv 패턴 개선

2. **새로운 경량 어텐션 메커니즘**
   - Coordinate Attention 적용
   - Spatial Attention 경량화 버전
   - Channel Shuffle 기반 어텐션

### 6.2 중기 개선 과제 (3-5일)
1. **아키텍처 혁신**
   - MobileNetV3 스타일 inverted residual
   - EfficientNet 스타일 compound scaling
   - NAS 기반 아키텍처 탐색

2. **훈련 전략 개선**
   - Progressive resizing (128→256)
   - Knowledge distillation from larger model
   - Ensemble 기법 (model averaging)

### 6.3 장기 연구 과제 (1주 이상)
1. **완전히 새로운 아키텍처**
   - Transformer 기반 경량 세그멘테이션
   - Neural Architecture Search (NAS)
   - 하드웨어 특화 최적화

2. **메타 러닝 접근**
   - Few-shot segmentation
   - Domain adaptation
   - Transfer learning 전략

---

## ⚠️ 7. 주의사항 및 제약사항

### 7.1 절대 준수 사항
- **파라미터 수 제한**: 10,000개 초과 금지
- **외부 데이터 사용 금지**: 주어진 5개 데이터셋만 사용
- **사전 훈련 모델 금지**: 모든 가중치를 처음부터 훈련
- **코어 노트북 수정 금지**: competition_main.ipynb, Model_Test.ipynb 수정 불가

### 7.2 허용된 수정 범위
- `models/` 디렉토리 내 Python 파일 추가/수정
- `training_args.py` 수정 (옵티마이저, 스케줄러, 손실함수)
- `requirements.txt` 업데이트

---

## 📁 8. 주요 파일 구조

```
CV_final/
├── models/submission_20221555/          # 학생 모델 디렉토리
│   ├── submission_MicroNetv13.py       # 최신 성능 모델
│   ├── submission_MicroNetv13_Ultimate.py  # 최종 시도 모델
│   ├── submission_test.py              # 최고 성능 모델 (0.4333 IoU)
│   └── [기타 83개 실험 모델들...]
├── training_args.py                     # 훈련 하이퍼파라미터
├── results.csv                         # 모든 실험 결과 로그
├── competition_main.ipynb              # 메인 훈련 노트북 (수정 금지)
├── Model_Test.ipynb                    # 모델 테스트 노트북 (수정 금지)
└── output/                             # 실험 결과 저장 디렉토리
```

---

## 🔄 9. 다음 작업자를 위한 체크리스트

### 9.1 시작하기 전에
- [ ] `results.csv`에서 현재까지의 실험 결과 분석
- [ ] 최고 성능 모델들 (`test`, `MicroNetv5`, `MicroNetv4`) 코드 분석
- [ ] `training_args.py`의 현재 하이퍼파라미터 설정 확인
- [ ] 10k 파라미터 제한 다시 한번 확인

### 9.2 실험 진행 시
- [ ] 새 모델 생성 시 기존 파일 수정보다는 새 파일 생성
- [ ] 파라미터 수 계산 코드로 사전 검증
- [ ] 실험 결과를 `results.csv`에 지속적으로 기록
- [ ] WarmupCosineLR 스케줄러 유지 (훈련 안정성 확보)

### 9.3 제출 준비 시
- [ ] 최종 모델 클래스명이 `submission_20221555`인지 확인
- [ ] 모든 requirements 업데이트
- [ ] GitHub 레포지토리 정리 및 공유 준비

---

## 📞 10. 문의 및 지원

### 10.1 기술적 문제
- **파라미터 계산 오류**: `competition_utils.py`의 parameter counting 함수 활용
- **메모리 부족**: 배치 크기는 고정이므로 모델 크기 조정 필요
- **수렴 문제**: 학습률 및 스케줄러 설정 재검토

### 10.2 참고 자료
- **프로젝트 안내서**: `컴퓨터비전_기말고사_프로젝트_안내_250611.pdf`
- **실험 로그**: `results.csv` 및 `output/` 디렉토리
- **코드 예시**: 기존 모델들의 구현 패턴 참고

---

## 🎉 마무리

이 프로젝트는 **83번의 실험**을 통해 극한의 파라미터 효율성과 세그멘테이션 성능 사이의 최적점을 찾아가는 도전적인 여정이었습니다. 

현재까지의 최고 성과인 **test 모델의 0.4333 IoU**는 20,274개의 파라미터로 달성되었으며, 더 적은 파라미터로도 **0.38+ IoU**를 달성할 수 있음을 입증했습니다.

다음 작업자께서는 이 경험과 인사이트를 바탕으로 더욱 혁신적인 솔루션을 개발하시길 바랍니다. **화이팅! 🚀**

---

*"모든 실패는 성공으로 가는 디딤돌이다. - Every failure is a stepping stone to success."* 