#!/usr/bin/env python3
"""
Optuna ì‹¤í—˜ í™˜ê²½ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ ì‹¤í—˜ ì „ì— ì„¤ì • ë° í™˜ê²½ì´ ì˜¬ë°”ë¥´ê²Œ êµ¬ì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
"""

import sys
import os
import importlib
import torch
from datetime import datetime

def test_imports():
    """í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ import í…ŒìŠ¤íŠ¸"""
    print("ğŸ” ë¼ì´ë¸ŒëŸ¬ë¦¬ Import í…ŒìŠ¤íŠ¸")
    
    try:
        import optuna
        print(f"  âœ… optuna {optuna.__version__}")
    except ImportError as e:
        print(f"  âŒ optuna ì„¤ì¹˜ í•„ìš”: {e}")
        return False
    
    try:
        import pandas as pd
        print(f"  âœ… pandas {pd.__version__}")
    except ImportError as e:
        print(f"  âŒ pandas ì„¤ì¹˜ í•„ìš”: {e}")
        return False
    
    try:
        import torch
        print(f"  âœ… torch {torch.__version__}")
        print(f"  ğŸ“± CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"  ğŸ® GPU ê°œìˆ˜: {torch.cuda.device_count()}")
    except ImportError as e:
        print(f"  âŒ torch ì„¤ì¹˜ í•„ìš”: {e}")
        return False
    
    try:
        from competition_utils import Execute_Experiment
        print("  âœ… competition_utils")
    except ImportError as e:
        print(f"  âŒ competition_utils ë¬¸ì œ: {e}")
        return False
    
    try:
        from training_args import Make_Optimizer, Make_LR_Scheduler, Make_Loss_Function
        print("  âœ… training_args")
    except ImportError as e:
        print(f"  âŒ training_args ë¬¸ì œ: {e}")
        return False
    
    return True

def test_config():
    """ì„¤ì • íŒŒì¼ í…ŒìŠ¤íŠ¸"""
    print("\nâš™ï¸ ì„¤ì • íŒŒì¼ í…ŒìŠ¤íŠ¸")
    
    try:
        from optuna_config import (
            EXPERIMENT_CONFIG, HYPERPARAMETER_SPACE, 
            validate_config, DATASET_CONFIG
        )
        print("  âœ… optuna_config import ì„±ê³µ")
        
        # ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬
        validate_config()
        print("  âœ… ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬ í†µê³¼")
        
        # ê¸°ë³¸ ì„¤ì • ì¶œë ¥
        print(f"  ğŸ“Š Target model: {EXPERIMENT_CONFIG['model_name']}")
        print(f"  ğŸ¯ Trial ìˆ˜: {EXPERIMENT_CONFIG['n_trials']}")
        print(f"  ğŸ” Search space í¬ê¸°: {len(HYPERPARAMETER_SPACE)}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ ì„¤ì • íŒŒì¼ ì˜¤ë¥˜: {e}")
        return False

def test_model_loading():
    """ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§  ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸")
    
    try:
        from optuna_config import EXPERIMENT_CONFIG
        student_id = EXPERIMENT_CONFIG['student_id']
        model_name = EXPERIMENT_CONFIG['model_name']
        
        model_name_full = f'submission_{model_name}'
        module_path = f"models.submission_{student_id}.{model_name_full}"
        
        print(f"  ğŸ” ëª¨ë“ˆ ê²½ë¡œ: {module_path}")
        
        module = importlib.import_module(module_path)
        model_class = getattr(module, model_name_full)
        
        print(f"  âœ… ëª¨ë¸ í´ë˜ìŠ¤ ë¡œë“œ ì„±ê³µ: {model_class}")
        
        # í…ŒìŠ¤íŠ¸ ëª¨ë¸ ìƒì„±
        test_model = model_class(3, 21)  # VOCìš© (3 channels, 21 classes)
        
        # íŒŒë¼ë¯¸í„° ìˆ˜ í™•ì¸
        total_params = sum(p.numel() for p in test_model.parameters() if p.requires_grad)
        print(f"  ğŸ“ ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}")
        
        if total_params > 10000:
            print(f"  âš ï¸ ê²½ê³ : íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì œí•œ(10,000)ì„ ì´ˆê³¼í•¨!")
        else:
            print(f"  âœ… íŒŒë¼ë¯¸í„° ì œí•œ ì¤€ìˆ˜")
        
        return True
        
    except Exception as e:
        print(f"  âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        return False

def test_data_paths():
    """ë°ì´í„°ì…‹ ê²½ë¡œ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“ ë°ì´í„°ì…‹ ê²½ë¡œ í…ŒìŠ¤íŠ¸")
    
    try:
        from optuna_config import DATASET_CONFIG
        dataset_root = DATASET_CONFIG['dataset_root']
        dataset_names = DATASET_CONFIG['dataset_names']
        
        print(f"  ğŸ“‚ ë°ì´í„°ì…‹ ë£¨íŠ¸: {dataset_root}")
        
        if not os.path.exists(dataset_root):
            print(f"  âŒ ë°ì´í„°ì…‹ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {dataset_root}")
            return False
        
        missing_datasets = []
        for dataset_name in dataset_names:
            dataset_path = os.path.join(dataset_root, dataset_name)
            if os.path.exists(dataset_path):
                print(f"  âœ… {dataset_name}")
                
                # train/val/test ë””ë ‰í† ë¦¬ í™•ì¸
                for split in ['train', 'val', 'test']:
                    split_path = os.path.join(dataset_path, split)
                    if os.path.exists(split_path):
                        orig_path = os.path.join(split_path, 'Originals')
                        mask_path = os.path.join(split_path, 'Masks')
                        
                        if os.path.exists(orig_path) and os.path.exists(mask_path):
                            orig_count = len(os.listdir(orig_path))
                            mask_count = len(os.listdir(mask_path))
                            print(f"      {split}: {orig_count} images, {mask_count} masks")
                        else:
                            print(f"      âš ï¸ {split}: Originals ë˜ëŠ” Masks í´ë” ì—†ìŒ")
            else:
                missing_datasets.append(dataset_name)
                print(f"  âŒ {dataset_name} - ê²½ë¡œ ì—†ìŒ: {dataset_path}")
        
        if missing_datasets:
            print(f"  âš ï¸ ëˆ„ë½ëœ ë°ì´í„°ì…‹: {missing_datasets}")
            return False
        
        return True
        
    except Exception as e:
        print(f"  âŒ ë°ì´í„°ì…‹ ê²½ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_optuna_functionality():
    """ê¸°ë³¸ Optuna ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”¬ Optuna ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    
    try:
        import optuna
        from optuna.samplers import TPESampler
        from optuna.pruners import MedianPruner
        
        # ê°„ë‹¨í•œ study ìƒì„± í…ŒìŠ¤íŠ¸
        def simple_objective(trial):
            x = trial.suggest_float('x', -10, 10)
            return (x - 2) ** 2
        
        study = optuna.create_study(direction='minimize')
        study.optimize(simple_objective, n_trials=3)
        
        print(f"  âœ… Optuna ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        print(f"  ğŸ¯ Best value: {study.best_value:.4f}")
        print(f"  ğŸ“Š Best params: {study.best_params}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Optuna ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_directory_permissions():
    """ë””ë ‰í† ë¦¬ ê¶Œí•œ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“ ë””ë ‰í† ë¦¬ ê¶Œí•œ í…ŒìŠ¤íŠ¸")
    
    try:
        # output ë””ë ‰í† ë¦¬ ìƒì„± í…ŒìŠ¤íŠ¸
        test_output_dir = "output/test_temp"
        os.makedirs(test_output_dir, exist_ok=True)
        
        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‘ì„±
        test_file = os.path.join(test_output_dir, "test.txt")
        with open(test_file, 'w') as f:
            f.write("test")
        
        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°
        with open(test_file, 'r') as f:
            content = f.read()
        
        # ì •ë¦¬
        os.remove(test_file)
        os.rmdir(test_output_dir)
        
        print("  âœ… output ë””ë ‰í† ë¦¬ ì½ê¸°/ì“°ê¸° ê¶Œí•œ í™•ì¸")
        
        # logs ë””ë ‰í† ë¦¬ í…ŒìŠ¤íŠ¸
        log_dir = "logs"
        os.makedirs(log_dir, exist_ok=True)
        print("  âœ… logs ë””ë ‰í† ë¦¬ ìƒì„± ê°€ëŠ¥")
        
        return True
        
    except Exception as e:
        print(f"  âŒ ë””ë ‰í† ë¦¬ ê¶Œí•œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ§ª Optuna ì‹¤í—˜ í™˜ê²½ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    tests = [
        test_imports,
        test_config,
        test_model_loading,
        test_data_paths,
        test_optuna_functionality,
        test_directory_permissions
    ]
    
    results = []
    for test_func in tests:
        try:
            result = test_func()
            results.append(result)
        except Exception as e:
            print(f"  ğŸ’¥ {test_func.__name__} ì˜ˆì™¸ ë°œìƒ: {e}")
            results.append(False)
    
    print("\n" + "=" * 50)
    print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    
    success_count = sum(results)
    total_count = len(results)
    
    for i, (test_func, result) in enumerate(zip(tests, results)):
        status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
        print(f"  {i+1}. {test_func.__name__}: {status}")
    
    print(f"\nğŸ¯ ì „ì²´ ê²°ê³¼: {success_count}/{total_count} í†µê³¼")
    
    if success_count == total_count:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! Optuna ì‹¤í—˜ ì¤€ë¹„ ì™„ë£Œ")
        print("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
        print("  1. ./run_optuna.sh ì‹¤í–‰")
        print("  2. ë˜ëŠ” python optuna_experiment.py ì§ì ‘ ì‹¤í–‰")
        return True
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ìœ„ì˜ ì˜¤ë¥˜ë¥¼ í•´ê²° í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 